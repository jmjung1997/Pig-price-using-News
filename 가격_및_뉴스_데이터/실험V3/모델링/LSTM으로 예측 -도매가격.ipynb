{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b837da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf35aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch import optim\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# 데이터 불러오기\n",
    "df_all=pd.read_csv('../data_v3/감성점수와 일별뉴스 합친거.csv',encoding='utf-8')\n",
    "df = df_all.iloc[:,[1,2,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb10ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\jm\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_all=pd.read_excel('../data_v3/전국경락단가.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b7e14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>도매가격_1</th>\n",
       "      <th>도매가격</th>\n",
       "      <th>day_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4104</td>\n",
       "      <td>4104</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4049</td>\n",
       "      <td>4049</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3920</td>\n",
       "      <td>3920</td>\n",
       "      <td>-0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>-0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4090</td>\n",
       "      <td>4090</td>\n",
       "      <td>-0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>4718</td>\n",
       "      <td>4718</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>4749</td>\n",
       "      <td>4749</td>\n",
       "      <td>-0.116270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>4820</td>\n",
       "      <td>4820</td>\n",
       "      <td>-0.116270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>4919</td>\n",
       "      <td>4919</td>\n",
       "      <td>-0.116270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>4988</td>\n",
       "      <td>4988</td>\n",
       "      <td>-0.116270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     도매가격_1  도매가격  day_sentiment\n",
       "0      4104  4104       0.000000\n",
       "1      4049  4049       0.000000\n",
       "2      3920  3920      -0.104167\n",
       "3      3917  3917      -0.104167\n",
       "4      4090  4090      -0.104167\n",
       "..      ...   ...            ...\n",
       "620    4718  4718       0.175000\n",
       "621    4749  4749      -0.116270\n",
       "622    4820  4820      -0.116270\n",
       "623    4919  4919      -0.116270\n",
       "624    4988  4988      -0.116270\n",
       "\n",
       "[625 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['경락단가_평균']=df_all['price']\n",
    "df['경락단가']=df_all['price']\n",
    "df_all\n",
    "\n",
    "df.columns=['도매가격_1', '도매가격', 'day_sentiment']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c96ae30",
   "metadata": {},
   "source": [
    "### 도매가격으로 도매가격 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd069e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG={'TRAIN_WINDOW_SIZE':10,\n",
    "   'PREDICT_SIZE':4 ,\n",
    "    'how_inputdim':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f55ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>도매가격_1</th>\n",
       "      <th>도매가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>4718</td>\n",
       "      <td>4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>4749</td>\n",
       "      <td>4749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>4820</td>\n",
       "      <td>4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>4919</td>\n",
       "      <td>4919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>4988</td>\n",
       "      <td>4988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     도매가격_1  도매가격\n",
       "620    4718  4718\n",
       "621    4749  4749\n",
       "622    4820  4820\n",
       "623    4919  4919\n",
       "624    4988  4988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df=df[['day_sentiment','경락단가_평균']]\n",
    "df=df[['도매가격_1','도매가격']]\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552417f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16604\\3470187902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Input scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seq_length' is not defined"
     ]
    }
   ],
   "source": [
    "# 5일간의 데이터가 입력으로 들어가고 batch size는 임의로 지정\n",
    "batch = 100\n",
    "CFG={'TRAIN_WINDOW_SIZE':10,\n",
    "   'PREDICT_SIZE':4 ,\n",
    "    'how_inputdim':1,\n",
    "    'data_dim':1,\n",
    "    'hidden_dim':10,\n",
    "    'LEARNING_RATE':0.001,\n",
    "    'nb_epochs':10}\n",
    "\n",
    "# 데이터를 역순으로 정렬하여 전체 데이터의 70% 학습, 30% 테스트에 사용\n",
    "train_size = int(len(df)*0.7)\n",
    "train_set = df[0:train_size]  \n",
    "test_set = df[train_size-seq_length:]\n",
    "\n",
    "# Input scale\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_set.iloc[:, :-1])\n",
    "\n",
    "train_set.iloc[:, :-1] = scaler_x.transform(train_set.iloc[:, :-1])\n",
    "test_set.iloc[:, :-1] = scaler_x.transform(test_set.iloc[:, :-1])\n",
    "\n",
    "# Output scale\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_set.iloc[:, [-1]])\n",
    "\n",
    "train_set.iloc[:, -1:] = scaler_y.transform(train_set.iloc[:, -1:])\n",
    "test_set.iloc[:, -1:] = scaler_y.transform(test_set.iloc[:, -1:])\n",
    "\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def build_dataset(time_series,train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    window_size = train_size + predict_size\n",
    "    for i in range(len(time_series) - window_size + 1):\n",
    "        _x = time_series[i:i+train_size, :-1]\n",
    "        _y = time_series[i+train_size:i+train_size+predict_size, [-1]]\n",
    "        # print(_x, \"-->\",_y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainX, trainY = build_dataset(np.array(train_set))\n",
    "testX, testY = build_dataset(np.array(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79769628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서로 변환\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184dffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(trainX, trainY)\n",
    "test_dataset= CustomDataset(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd072bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서로 변환\n",
    "'''trainX_tensor = torch.FloatTensor(trainX)\n",
    "trainY_tensor = torch.FloatTensor(trainY)\n",
    "testX_tensor = torch.FloatTensor(testX)\n",
    "testY_tensor = torch.FloatTensor(testY)'''\n",
    "'''# 텐서 형태로 데이터 정의\n",
    "dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
    "val_dataset=TensorDataset(testX_tensor, testY_tensor)'''\n",
    "\n",
    "# 데이터로더는 기본적으로 2개의 인자를 입력받으며 배치크기는 통상적으로 2의 배수를 사용\n",
    "dataloader = DataLoader(train_dataset,\n",
    "                        batch_size=batch,\n",
    "                        shuffle=True,  \n",
    "                        drop_last=True)\n",
    "\n",
    "\n",
    "val_dataloader=DataLoader(test_dataset,\n",
    "                        batch_size=batch,\n",
    "                        shuffle=True,  \n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden_size//2, output_size)\n",
    "        )\n",
    "            \n",
    "        self.actv = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, TRAIN_WINDOW_SIZE, 5)\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size, x.device)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # Only use the last output sequence\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        # Fully connected layer\n",
    "        output = self.actv(self.fc(last_output))\n",
    "        return output.squeeze(1)\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Initialize hidden state and cell state\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size, device=device))    \n",
    "    \n",
    "def train(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    best_loss = 9999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['nb_epochs']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_mae = []\n",
    "        for X, Y in tqdm(iter(train_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "        \n",
    "            loss = criterion(output[1], Y[1])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = validation(model, val_loader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            print('Model Saved')\n",
    "    return best_model\n",
    "\n",
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(iter(val_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            output = model(X)\n",
    "            loss = criterion(output[1], Y[1])\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "# 모델 학습\n",
    "model = Net(CFG['how_inputdim'], CFG['hidden_dim'], CFG['PREDICT_SIZE']).to(device)  \n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "infer_model = train(model, optimizer, dataloader, val_dataloader, device)\n",
    "# epoch별 손실값\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "#plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# # 모델 저장    \n",
    "# PATH = \"./Timeseries_LSTM_data-02-stock_daily_3.pth\"\n",
    "# torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# # 불러오기\n",
    "# model = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "# model.load_state_dict(torch.load(PATH), strict=False)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc0a13",
   "metadata": {},
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910a69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, val_dataloader,device):\n",
    "    model.eval()\n",
    "    # 예측 테스트\n",
    "    with torch.no_grad(): \n",
    "        pred = []\n",
    "        for X, Y in tqdm(iter(val_dataloader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            output = model(X)\n",
    "           \n",
    "            pred.extend(output)\n",
    "           \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48f2d4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'infer_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16604\\2137241621.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfer_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'infer_model' is not defined"
     ]
    }
   ],
   "source": [
    "pred= inference(infer_model, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1affca59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16604\\3252189334.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# INVERSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred_inverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtestY_inverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler_y' is not defined"
     ]
    }
   ],
   "source": [
    "# INVERSE\n",
    "pred_inverse = scaler_y.inverse_transform(pred.cpu())\n",
    "testY_inverse = scaler_y.inverse_transform(testY_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "706a6654",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16604\\1076283896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for i in val_dataloader:\n",
    "    print(i[1])\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d031dfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04a3e7",
   "metadata": {},
   "source": [
    "pred= inference(infer_model, val_dataloader, device)\n",
    "\n",
    "def inference(model, val_dataloader, device):\n",
    "    pred = []\n",
    "    with torch.no_grad(): \n",
    "        for x in tqdm(iter(val_dataloader)):\n",
    "            print(x[0])\n",
    "            X = x[0].to(device)   \n",
    "            output = model(X)\n",
    "            output = output.cpu().numpy()\n",
    "            pred.extend(output)\n",
    "            predicted=np.array(pred)\n",
    "    return predicted\n",
    "\n",
    "pred= inference(infer_model, val_dataloader, device)\n",
    "\n",
    "# INVERSE\n",
    "pred_inverse = scaler_y.inverse_transform(pred)\n",
    "testY_inverse = scaler_y.inverse_transform(test_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "29973fa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,4) (188,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1660\\3207093023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MAE SCORE : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY_inverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#MAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1660\\3207093023.py\u001b[0m in \u001b[0;36mMAE\u001b[1;34m(true, pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MAE SCORE : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY_inverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,4) (188,1) "
     ]
    }
   ],
   "source": [
    "def MAE(true, pred):\n",
    "    return np.mean(np.abs(true-pred))\n",
    "\n",
    "print('MAE SCORE : ', MAE(pred_inverse, testY_inverse))\n",
    "\n",
    "#MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE\",mean_absolute_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"MSE\",mean_squared_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#RMSE\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(testY_inverse,pred_inverse)\n",
    "print(\"MSE\",np.sqrt(MSE))\n",
    "# sklearn 은 mse만 제공하기 때문에 rmse는 직접 만들어 써야한다.\n",
    "\n",
    "#MAPE\n",
    "import numpy as np\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "\treturn np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "print(\"MAPE\",MAPE(testY_inverse, pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.plot(np.arange(len(pred_inverse)), pred_inverse, label = 'pred')\n",
    "plt.plot(np.arange(len(testY_inverse)), testY_inverse, label = 'true')\n",
    "plt.title(\"도매가격->도매가격\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240991d",
   "metadata": {},
   "source": [
    "### 도매가격+감성점수-> 도매가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "466ac432",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (3556978065.py, line 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\jaemin\\AppData\\Local\\Temp\\ipykernel_1660\\3556978065.py\"\u001b[1;36m, line \u001b[1;32m69\u001b[0m\n\u001b[1;33m    def __init__(self, input_size=CFG['how_inputdim'],hidden_dim=CFG['hidden_dim'], seq_len=CFG['TRAIN_WINDOW_SIZE'], PREDICT_SIZE=CFG['PREDICT_SIZE'], layers):\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "# 5일간의 데이터가 입력으로 들어가고 batch size는 임의로 지정\n",
    "batch = 100\n",
    "CFG={'TRAIN_WINDOW_SIZE':10,\n",
    "   'PREDICT_SIZE':4 ,\n",
    "    'how_inputdim':1,\n",
    "    'data_dim':1,\n",
    "    'hidden_dim':10,\n",
    "    'learning_rate':0.001,\n",
    "    'nb_epochs':100}\n",
    "\n",
    "\n",
    "# 데이터를 역순으로 정렬하여 전체 데이터의 70% 학습, 30% 테스트에 사용\n",
    "train_size = int(len(df)*0.7)\n",
    "train_set = df[0:train_size]  \n",
    "test_set = df[train_size-CFG['TRAIN_WINDOW_SIZE']:]\n",
    "\n",
    "# Input scale\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_set.iloc[:, :-1])\n",
    "\n",
    "train_set.iloc[:, :-1] = scaler_x.transform(train_set.iloc[:, :-1])\n",
    "test_set.iloc[:, :-1] = scaler_x.transform(test_set.iloc[:, :-1])\n",
    "\n",
    "# Output scale\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_set.iloc[:, [-1]])\n",
    "\n",
    "train_set.iloc[:, -1:] = scaler_y.transform(train_set.iloc[:, -1:])\n",
    "test_set.iloc[:, -1:] = scaler_y.transform(test_set.iloc[:, -1:])\n",
    "\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def build_dataset(time_series,train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    window_size = train_size + predict_size\n",
    "    for i in range(len(time_series) - window_size + 1):\n",
    "        _x = time_series[i:i+train_size, :-1]\n",
    "        _y = time_series[i+predict_size, [-1]]\n",
    "        # print(_x, \"-->\",_y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = build_dataset(np.array(train_set))\n",
    "testX, testY = build_dataset(np.array(test_set))\n",
    "\n",
    "# 텐서로 변환\n",
    "trainX_tensor = torch.FloatTensor(trainX)\n",
    "trainY_tensor = torch.FloatTensor(trainY)\n",
    "testX_tensor = torch.FloatTensor(testX)\n",
    "testY_tensor = torch.FloatTensor(testY)\n",
    "\n",
    "# 텐서 형태로 데이터 정의\n",
    "dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
    "\n",
    "# 데이터로더는 기본적으로 2개의 인자를 입력받으며 배치크기는 통상적으로 2의 배수를 사용\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch,\n",
    "                        shuffle=True,  \n",
    "                        drop_last=True)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # # 기본변수, layer를 초기화해주는 생성자\n",
    "    def __init__(self, input_size=CFG['how_inputdim'],hidden_dim=CFG['hidden_dim'], seq_len=CFG['TRAIN_WINDOW_SIZE'], PREDICT_SIZE=CFG['PREDICT_SIZE'], layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = PREDICT_SIZE\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=layers,\n",
    "                            # dropout = 0.1,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, PREDICT_SIZE, bias = True) \n",
    "        \n",
    "    # 학습 초기화를 위한 함수\n",
    "    def reset_hidden_state(self): \n",
    "        self.hidden = (\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim),\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim))\n",
    "    \n",
    "    # 예측을 위한 함수\n",
    "    def forward(self, x):\n",
    "        x, _status = self.lstm(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        #print(\"x.shape\",x.shape)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_df, num_epochs = None, lr = None, verbose = 10, patience = 10):\n",
    "     \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    nb_epochs = num_epochs\n",
    "    \n",
    "    # epoch마다 loss 저장\n",
    "    train_hist = np.zeros(nb_epochs)\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = len(train_df)\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_df):\n",
    "\n",
    "            x_train, y_train = samples\n",
    "            x_train=x_train.to(device)\n",
    "            y_train=y_train.to(device)\n",
    "            # seq별 hidden state reset\n",
    "            model.reset_hidden_state()\n",
    "            \n",
    "            # H(x) 계산\n",
    "            outputs = model(x_train)\n",
    "                \n",
    "            # cost 계산\n",
    "            loss = criterion(outputs, y_train)                    \n",
    "            \n",
    "            # cost로 H(x) 개선\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_cost += loss/total_batch\n",
    "               \n",
    "        train_hist[epoch] = avg_cost        \n",
    "        \n",
    "        if epoch % verbose == 0:\n",
    "            print('Epoch:', '%04d' % (epoch), 'train loss :', '{:.4f}'.format(avg_cost))\n",
    "            \n",
    "        # patience번째 마다 early stopping 여부 확인\n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "            \n",
    "            # loss가 커졌다면 early stop\n",
    "            if train_hist[epoch-patience] < train_hist[epoch]:\n",
    "                print('\\n Early Stopping')\n",
    "                \n",
    "                break\n",
    "            \n",
    "    return model.eval(), train_hist\n",
    "\n",
    "# 모델 학습\n",
    "net = Net(data_dim, hidden_dim, seq_length, PREDICT_SIZE, 1).to(device)  \n",
    "model, train_hist = train_model(net, dataloader, num_epochs = nb_epochs, lr = learning_rate, verbose = 20, patience = 10)\n",
    "\n",
    "# epoch별 손실값\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 저장    \n",
    "PATH = \"./Timeseries_LSTM_data-02-stock_daily_.pth\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# 불러오기\n",
    "model = Net(data_dim, hidden_dim, seq_length, PREDICT_SIZE, 1).to(device)  \n",
    "model.load_state_dict(torch.load(PATH), strict=False)\n",
    "model.eval()\n",
    "\n",
    "# 예측 테스트\n",
    "with torch.no_grad(): \n",
    "    pred = []\n",
    "    for pr in range(len(testX_tensor)):\n",
    "\n",
    "        model.reset_hidden_state()\n",
    "\n",
    "        predicted = model(torch.unsqueeze(testX_tensor[pr], 0).to(device) )\n",
    "        predicted = torch.flatten(predicted).item()\n",
    "        pred.append(predicted)\n",
    "\n",
    "    # INVERSE\n",
    "    pred_inverse = scaler_y.inverse_transform(np.array(pred).reshape(-1, 1))\n",
    "    testY_inverse = scaler_y.inverse_transform(testY_tensor)\n",
    "\n",
    "def MAE(true, pred):\n",
    "    return np.mean(np.abs(true-pred))\n",
    "\n",
    "print('MAE SCORE : ', MAE(pred_inverse, testY_inverse))\n",
    "\n",
    "#MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE\",mean_absolute_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"MSE\",mean_squared_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#RMSE\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(testY_inverse,pred_inverse)\n",
    "print(\"MSE\",np.sqrt(MSE))\n",
    "# sklearn 은 mse만 제공하기 때문에 rmse는 직접 만들어 써야한다.\n",
    "\n",
    "#MAPE\n",
    "import numpy as np\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "\treturn np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "print(\"MAPE\",MAPE(testY_inverse, pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbedad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df_all=pd.read_csv('../data_v3/감성점수와 일별뉴스 합친거.csv',encoding='utf-8')\n",
    "df = df_all.iloc[:,[1,2,5]]\n",
    "\n",
    "df_all=pd.read_excel('../data_v3/전국경락단가.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a587764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(data, train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    '''\n",
    "    학습 기간 블럭, 예측 기간 블럭의 세트로 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 학습에 활용할 기간\n",
    "    predict_size : 추론할 기간\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    window_size = train_size + predict_size\n",
    "    \n",
    "    input_data = np.empty((num_rows * (len(data.columns) - window_size + 1), train_size, len(data.iloc[0, :CFG['how_inputdim']]) + 1))\n",
    "    target_data = np.empty((num_rows * (len(data.columns) - window_size + 1), predict_size))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :CFG['how_inputdim']])\n",
    "        sales_data = np.array(data.iloc[i, CFG['how_inputdim']:])\n",
    "        \n",
    "        for j in range(len(sales_data) - window_size + 1):\n",
    "            window = sales_data[j : j + window_size]\n",
    "            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "            input_data[i * (len(data.columns) - window_size + 1) + j] = temp_data\n",
    "            target_data[i * (len(data.columns) - window_size + 1) + j] = window[train_size:]\n",
    "    \n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30988614",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = make_train_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['경락단가_평균']=df_all['price']\n",
    "df['경락단가']=df_all['price']\n",
    "df_all\n",
    "\n",
    "df.columns=['도매가격_1', '도매가격', 'day_sentiment']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG['how_inputdim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af365871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df[['day_sentiment','경락단가_평균']]\n",
    "df=df[['day_sentiment','도매가격']]\n",
    "\n",
    "\n",
    "# 7일간의 데이터가 입력으로 들어가고 batch size는 임의로 지정\n",
    "seq_length = 5\n",
    "batch = 100\n",
    "\n",
    "# 데이터를 역순으로 정렬하여 전체 데이터의 70% 학습, 30% 테스트에 사용\n",
    "train_size = int(len(df)*0.7)\n",
    "train_set = df[0:train_size]  \n",
    "test_set = df[train_size-seq_length:]\n",
    "\n",
    "# Input scale\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_set.iloc[:, :-1])\n",
    "\n",
    "train_set.iloc[:, :-1] = scaler_x.transform(train_set.iloc[:, :-1])\n",
    "test_set.iloc[:, :-1] = scaler_x.transform(test_set.iloc[:, :-1])\n",
    "\n",
    "# Output scale\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_set.iloc[:, [-1]])\n",
    "\n",
    "train_set.iloc[:, -1:] = scaler_y.transform(train_set.iloc[:, -1:])\n",
    "test_set.iloc[:, -1:] = scaler_y.transform(test_set.iloc[:, -1:])\n",
    "\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series)-seq_length):\n",
    "        _x = time_series[i:i+seq_length, :]\n",
    "        _y = time_series[i+seq_length, [-1]]\n",
    "        # print(_x, \"-->\",_y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = build_dataset(np.array(train_set), seq_length)\n",
    "testX, testY = build_dataset(np.array(test_set), seq_length)\n",
    "\n",
    "# 텐서로 변환\n",
    "trainX_tensor = torch.FloatTensor(trainX)\n",
    "trainY_tensor = torch.FloatTensor(trainY)\n",
    "testX_tensor = torch.FloatTensor(testX)\n",
    "testY_tensor = torch.FloatTensor(testY)\n",
    "\n",
    "# 텐서 형태로 데이터 정의\n",
    "dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
    "\n",
    "# 데이터로더는 기본적으로 2개의 인자를 입력받으며 배치크기는 통상적으로 2의 배수를 사용\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch,\n",
    "                        shuffle=True,  \n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ebc22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation Split\n",
    "data_len = len(train_input)\n",
    "val_input = train_input[-int(data_len*0.2):]\n",
    "val_target = train_target[-int(data_len*0.2):]\n",
    "train_input = train_input[:-int(data_len*0.2)]\n",
    "train_target = train_target[:-int(data_len*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_input, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in dataset:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8621fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정값\n",
    "data_dim = 2\n",
    "hidden_dim = 10 \n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 100\n",
    "class Net(nn.Module):\n",
    "    # # 기본변수, layer를 초기화해주는 생성자\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len, output_dim, layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=layers,\n",
    "                            # dropout = 0.1,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim, bias = True) \n",
    "        \n",
    "    # 학습 초기화를 위한 함수\n",
    "    def reset_hidden_state(self): \n",
    "        self.hidden = (\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim),\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim))\n",
    "    \n",
    "    # 예측을 위한 함수\n",
    "    def forward(self, x):\n",
    "        x, _status = self.lstm(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_df, num_epochs = None, lr = None, verbose = 10, patience = 10):\n",
    "     \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    nb_epochs = num_epochs\n",
    "    \n",
    "    # epoch마다 loss 저장\n",
    "    train_hist = np.zeros(nb_epochs)\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = len(train_df)\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_df):\n",
    "\n",
    "            x_train, y_train = samples\n",
    "            x_train=x_train.to(device)\n",
    "            y_train=y_train.to(device)\n",
    "            #print(\"x_train\",x_train)\n",
    "            # seq별 hidden state reset\n",
    "            model.reset_hidden_state()\n",
    "            \n",
    "            # H(x) 계산\n",
    "            outputs = model(x_train)\n",
    "                \n",
    "            # cost 계산\n",
    "            loss = criterion(outputs, y_train)                    \n",
    "            \n",
    "            # cost로 H(x) 개선\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_cost += loss/total_batch\n",
    "               \n",
    "        train_hist[epoch] = avg_cost        \n",
    "        \n",
    "        if epoch % verbose == 0:\n",
    "            print('Epoch:', '%04d' % (epoch), 'train loss :', '{:.4f}'.format(avg_cost))\n",
    "            \n",
    "        # patience번째 마다 early stopping 여부 확인\n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "            \n",
    "            # loss가 커졌다면 early stop\n",
    "            if train_hist[epoch-patience] < train_hist[epoch]:\n",
    "                print('\\n Early Stopping')\n",
    "                \n",
    "                break\n",
    "            \n",
    "    return model.eval(), train_hist\n",
    "\n",
    "# 모델 학습\n",
    "net = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "model, train_hist = train_model(net, dataloader, num_epochs = nb_epochs, lr = learning_rate, verbose = 20, patience = 10)\n",
    "\n",
    "# epoch별 손실값\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 저장    \n",
    "PATH = \"./Timeseries_LSTM_data-02-stock_daily_3.pth\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# 불러오기\n",
    "model = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "model.load_state_dict(torch.load(PATH), strict=False)\n",
    "model.eval()\n",
    "\n",
    "# 예측 테스트\n",
    "with torch.no_grad(): \n",
    "    pred = []\n",
    "    for pr in range(len(testX_tensor)):\n",
    "\n",
    "        model.reset_hidden_state()\n",
    "\n",
    "        predicted = model(torch.unsqueeze(testX_tensor[pr], 0).to(device) )\n",
    "        predicted = torch.flatten(predicted).item()\n",
    "        pred.append(predicted)\n",
    "\n",
    "    # INVERSE\n",
    "    pred_inverse = scaler_y.inverse_transform(np.array(pred).reshape(-1, 1))\n",
    "    testY_inverse = scaler_y.inverse_transform(testY_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0da35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(true, pred):\n",
    "    return np.mean(np.abs(true-pred))\n",
    "\n",
    "print('MAE SCORE : ', MAE(pred_inverse, testY_inverse))\n",
    "\n",
    "#MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE\",mean_absolute_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"MSE\",mean_squared_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#RMSE\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(testY_inverse,pred_inverse)\n",
    "print(\"MSE\",np.sqrt(MSE))\n",
    "# sklearn 은 mse만 제공하기 때문에 rmse는 직접 만들어 써야한다.\n",
    "\n",
    "#MAPE\n",
    "import numpy as np\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "\treturn np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "print(\"MAPE\",MAPE(testY_inverse, pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.plot(np.arange(len(pred_inverse)), pred_inverse, label = 'pred')\n",
    "plt.plot(np.arange(len(testY_inverse)), testY_inverse, label = 'true')\n",
    "plt.title(\"도매가격+감성점수->도매가격\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf4728c",
   "metadata": {},
   "source": [
    "# 경락단가->도매가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "820d05bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['경락단가'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1660\\917341868.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#df=df[['day_sentiment','경락단가_평균']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'경락단가'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'도매가격'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 7일간의 데이터가 입력으로 들어가고 batch size는 임의로 지정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\jm\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\jm\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\jm\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['경락단가'] not in index\""
     ]
    }
   ],
   "source": [
    "#df=df[['day_sentiment','경락단가_평균']]\n",
    "df=df[['경락단가','도매가격']]\n",
    "\n",
    "\n",
    "# 7일간의 데이터가 입력으로 들어가고 batch size는 임의로 지정\n",
    "seq_length = 5\n",
    "batch = 100\n",
    "\n",
    "# 데이터를 역순으로 정렬하여 전체 데이터의 70% 학습, 30% 테스트에 사용\n",
    "train_size = int(len(df)*0.7)\n",
    "train_set = df[0:train_size]  \n",
    "test_set = df[train_size-seq_length:]\n",
    "\n",
    "# Input scale\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_set.iloc[:, :-1])\n",
    "\n",
    "train_set.iloc[:, :-1] = scaler_x.transform(train_set.iloc[:, :-1])\n",
    "test_set.iloc[:, :-1] = scaler_x.transform(test_set.iloc[:, :-1])\n",
    "\n",
    "# Output scale\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_set.iloc[:, [-1]])\n",
    "\n",
    "train_set.iloc[:, -1:] = scaler_y.transform(train_set.iloc[:, -1:])\n",
    "test_set.iloc[:, -1:] = scaler_y.transform(test_set.iloc[:, -1:])\n",
    "\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series)-seq_length):\n",
    "        _x = time_series[i:i+seq_length, :]\n",
    "        _y = time_series[i+seq_length, [-1]]\n",
    "        # print(_x, \"-->\",_y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = build_dataset(np.array(train_set), seq_length)\n",
    "testX, testY = build_dataset(np.array(test_set), seq_length)\n",
    "\n",
    "# 텐서로 변환\n",
    "trainX_tensor = torch.FloatTensor(trainX)\n",
    "trainY_tensor = torch.FloatTensor(trainY)\n",
    "testX_tensor = torch.FloatTensor(testX)\n",
    "testY_tensor = torch.FloatTensor(testY)\n",
    "\n",
    "# 텐서 형태로 데이터 정의\n",
    "dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
    "\n",
    "# 데이터로더는 기본적으로 2개의 인자를 입력받으며 배치크기는 통상적으로 2의 배수를 사용\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch,\n",
    "                        shuffle=True,  \n",
    "                        drop_last=True)\n",
    "\n",
    "# 설정값\n",
    "data_dim = 1\n",
    "hidden_dim = 10 \n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 100\n",
    "class Net(nn.Module):\n",
    "    # # 기본변수, layer를 초기화해주는 생성자\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len, output_dim, layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=layers,\n",
    "                            # dropout = 0.1,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim, bias = True) \n",
    "        \n",
    "    # 학습 초기화를 위한 함수\n",
    "    def reset_hidden_state(self): \n",
    "        self.hidden = (\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim),\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim))\n",
    "    \n",
    "    # 예측을 위한 함수\n",
    "    def forward(self, x):\n",
    "        x, _status = self.lstm(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_df, num_epochs = None, lr = None, verbose = 10, patience = 10):\n",
    "     \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    nb_epochs = num_epochs\n",
    "    \n",
    "    # epoch마다 loss 저장\n",
    "    train_hist = np.zeros(nb_epochs)\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = len(train_df)\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_df):\n",
    "\n",
    "            x_train, y_train = samples\n",
    "            x_train=x_train.to(device)\n",
    "            y_train=y_train.to(device)\n",
    "            #print(\"x_train\",x_train)\n",
    "            # seq별 hidden state reset\n",
    "            model.reset_hidden_state()\n",
    "            \n",
    "            # H(x) 계산\n",
    "            outputs = model(x_train)\n",
    "                \n",
    "            # cost 계산\n",
    "            loss = criterion(outputs, y_train)                    \n",
    "            \n",
    "            # cost로 H(x) 개선\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_cost += loss/total_batch\n",
    "               \n",
    "        train_hist[epoch] = avg_cost        \n",
    "        \n",
    "        if epoch % verbose == 0:\n",
    "            print('Epoch:', '%04d' % (epoch), 'train loss :', '{:.4f}'.format(avg_cost))\n",
    "            \n",
    "        # patience번째 마다 early stopping 여부 확인\n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "            \n",
    "            # loss가 커졌다면 early stop\n",
    "            if train_hist[epoch-patience] < train_hist[epoch]:\n",
    "                print('\\n Early Stopping')\n",
    "                \n",
    "                break\n",
    "            \n",
    "    return model.eval(), train_hist\n",
    "\n",
    "# 모델 학습\n",
    "net = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "model, train_hist = train_model(net, dataloader, num_epochs = nb_epochs, lr = learning_rate, verbose = 20, patience = 10)\n",
    "\n",
    "# epoch별 손실값\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 저장    \n",
    "PATH = \"./Timeseries_LSTM_data-02-stock_daily_2.pth\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# 불러오기\n",
    "model = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "model.load_state_dict(torch.load(PATH), strict=False)\n",
    "model.eval()\n",
    "\n",
    "# 예측 테스트\n",
    "with torch.no_grad(): \n",
    "    pred = []\n",
    "    for pr in range(len(testX_tensor)):\n",
    "\n",
    "        model.reset_hidden_state()\n",
    "\n",
    "        predicted = model(torch.unsqueeze(testX_tensor[pr], 0).to(device) )\n",
    "        predicted = torch.flatten(predicted).item()\n",
    "        pred.append(predicted)\n",
    "\n",
    "    # INVERSE\n",
    "    pred_inverse = scaler_y.inverse_transform(np.array(pred).reshape(-1, 1))\n",
    "    testY_inverse = scaler_y.inverse_transform(testY_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad81d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df_all=pd.read_csv('../data_v3/감성점수와 일별뉴스 합친거.csv',encoding='utf-8')\n",
    "df = df_all.iloc[:,[1,2,5]]\n",
    "\n",
    "df_all=pd.read_excel('../data_v3/전국경락단가.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e6263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['경락단가_평균']=df_all['price']\n",
    "\n",
    "df_all\n",
    "\n",
    "df.columns=['경락단가', '도매가격', 'day_sentiment']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c487214",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbbae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df[['day_sentiment','경락단가_평균']]\n",
    "df=df[['경락단가','도매가격']]\n",
    "\n",
    "\n",
    "# 7일간의 데이터가 입력으로 들어가고 batch size는 임의로 지정\n",
    "seq_length = 5\n",
    "batch = 100\n",
    "\n",
    "# 데이터를 역순으로 정렬하여 전체 데이터의 70% 학습, 30% 테스트에 사용\n",
    "train_size = int(len(df)*0.7)\n",
    "train_set = df[0:train_size]  \n",
    "test_set = df[train_size-seq_length:]\n",
    "\n",
    "# Input scale\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_set.iloc[:, :-1])\n",
    "\n",
    "train_set.iloc[:, :-1] = scaler_x.transform(train_set.iloc[:, :-1])\n",
    "test_set.iloc[:, :-1] = scaler_x.transform(test_set.iloc[:, :-1])\n",
    "\n",
    "# Output scale\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_set.iloc[:, [-1]])\n",
    "\n",
    "train_set.iloc[:, -1:] = scaler_y.transform(train_set.iloc[:, -1:])\n",
    "test_set.iloc[:, -1:] = scaler_y.transform(test_set.iloc[:, -1:])\n",
    "\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series)-seq_length):\n",
    "        _x = time_series[i:i+seq_length, :-1]\n",
    "        _y = time_series[i+seq_length, [-1]]\n",
    "    \n",
    "        # print(_x, \"-->\",_y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = build_dataset(np.array(train_set), seq_length)\n",
    "testX, testY = build_dataset(np.array(test_set), seq_length)\n",
    "\n",
    "# 텐서로 변환\n",
    "trainX_tensor = torch.FloatTensor(trainX)\n",
    "trainY_tensor = torch.FloatTensor(trainY)\n",
    "testX_tensor = torch.FloatTensor(testX)\n",
    "testY_tensor = torch.FloatTensor(testY)\n",
    "\n",
    "# 텐서 형태로 데이터 정의\n",
    "dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
    "val_dataset=TensorDataset(testX_tensor, testY_tensor)\n",
    "# 데이터로더는 기본적으로 2개의 인자를 입력받으며 배치크기는 통상적으로 2의 배수를 사용\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch,\n",
    "                        shuffle=True,  \n",
    "                        drop_last=True)\n",
    "\n",
    "\n",
    "val_dataloader=DataLoader(val_dataset,\n",
    "                        batch_size=batch,\n",
    "                        shuffle=True,  \n",
    "                        drop_last=True)\n",
    "\n",
    "# 설정값\n",
    "data_dim = 1\n",
    "hidden_dim = 10 \n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 100\n",
    "class Net(nn.Module):\n",
    "    # # 기본변수, layer를 초기화해주는 생성자\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len, output_dim, layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=layers,\n",
    "                            # dropout = 0.1,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim, bias = True) \n",
    "        \n",
    "    # 학습 초기화를 위한 함수\n",
    "    def reset_hidden_state(self): \n",
    "        self.hidden = (\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim),\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim))\n",
    "    \n",
    "    # 예측을 위한 함수\n",
    "    def forward(self, x):\n",
    "        x, _status = self.lstm(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_df, num_epochs = None, lr = None, verbose = 10, patience = 10):\n",
    "     \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    nb_epochs = num_epochs\n",
    "    \n",
    "    # epoch마다 loss 저장\n",
    "    train_hist = np.zeros(nb_epochs)\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = len(train_df)\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_df):\n",
    "\n",
    "            x_train, y_train = samples\n",
    "            x_train=x_train.to(device)\n",
    "            y_train=y_train.to(device)\n",
    "            #print(\"x_train\",x_train)\n",
    "            # seq별 hidden state reset\n",
    "            model.reset_hidden_state()\n",
    "            \n",
    "            # H(x) 계산\n",
    "            outputs = model(x_train)\n",
    "                \n",
    "            # cost 계산\n",
    "            loss = criterion(outputs, y_train)                    \n",
    "            \n",
    "            # cost로 H(x) 개선\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_cost += loss/total_batch\n",
    "               \n",
    "        train_hist[epoch] = avg_cost        \n",
    "        \n",
    "        if epoch % verbose == 0:\n",
    "            print('Epoch:', '%04d' % (epoch), 'train loss :', '{:.4f}'.format(avg_cost))\n",
    "            \n",
    "        # patience번째 마다 early stopping 여부 확인\n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "            \n",
    "            # loss가 커졌다면 early stop\n",
    "            if train_hist[epoch-patience] < train_hist[epoch]:\n",
    "                print('\\n Early Stopping')\n",
    "                \n",
    "                break\n",
    "            \n",
    "    return model.eval(), train_hist\n",
    "\n",
    "# 모델 학습\n",
    "net = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "model, train_hist = train_model(net, dataloader, num_epochs = nb_epochs, lr = learning_rate, verbose = 20, patience = 10)\n",
    "\n",
    "# epoch별 손실값\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 저장    \n",
    "PATH = \"./Timeseries_LSTM_data-02-stock_daily_2.pth\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# 불러오기\n",
    "model = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "model.load_state_dict(torch.load(PATH), strict=False)\n",
    "model.eval()\n",
    "\n",
    "# 예측 테스트\n",
    "with torch.no_grad(): \n",
    "    pred = []\n",
    "    for pr in range(len(testX_tensor)):\n",
    "\n",
    "        model.reset_hidden_state()\n",
    "\n",
    "        predicted = model(torch.unsqueeze(testX_tensor[pr], 0).to(device) )\n",
    "        predicted = torch.flatten(predicted).item()\n",
    "        pred.append(predicted)\n",
    "\n",
    "    # INVERSE\n",
    "    pred_inverse = scaler_y.inverse_transform(np.array(pred).reshape(-1, 1))\n",
    "    testY_inverse = scaler_y.inverse_transform(testY_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc844d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(true, pred):\n",
    "    return np.mean(np.abs(true-pred))\n",
    "\n",
    "print('MAE SCORE : ', MAE(pred_inverse, testY_inverse))\n",
    "\n",
    "#MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE\",mean_absolute_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"MSE\",mean_squared_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#RMSE\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(testY_inverse,pred_inverse)\n",
    "print(\"MSE\",np.sqrt(MSE))\n",
    "# sklearn 은 mse만 제공하기 때문에 rmse는 직접 만들어 써야한다.\n",
    "\n",
    "#MAPE\n",
    "import numpy as np\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "\treturn np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "print(\"MAPE\",MAPE(testY_inverse, pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1590ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.plot(np.arange(len(pred_inverse)), pred_inverse, label = 'pred')\n",
    "plt.plot(np.arange(len(testY_inverse)), testY_inverse, label = 'true')\n",
    "plt.title(\"경락단가->도매가격\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207bd92",
   "metadata": {},
   "source": [
    "# 경락단가+감성점수->도매가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d738b307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\jm\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "df_all=pd.read_csv('../data_v3/감성점수와 일별뉴스 합친거.csv',encoding='utf-8')\n",
    "df = df_all.iloc[:,[1,2,5]]\n",
    "\n",
    "df_all=pd.read_excel('../data_v3/전국경락단가.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bdecd582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>경락단가</th>\n",
       "      <th>도매가격</th>\n",
       "      <th>day_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3750.366093</td>\n",
       "      <td>4104</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3547.574932</td>\n",
       "      <td>4049</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3696.060897</td>\n",
       "      <td>3920</td>\n",
       "      <td>-0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3770.156364</td>\n",
       "      <td>3917</td>\n",
       "      <td>-0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3809.974684</td>\n",
       "      <td>4090</td>\n",
       "      <td>-0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>4547.071429</td>\n",
       "      <td>4718</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>4373.212544</td>\n",
       "      <td>4749</td>\n",
       "      <td>-0.116270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>4278.649485</td>\n",
       "      <td>4820</td>\n",
       "      <td>-0.116270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>4322.080986</td>\n",
       "      <td>4919</td>\n",
       "      <td>-0.116270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>4138.037190</td>\n",
       "      <td>4988</td>\n",
       "      <td>-0.116270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            경락단가  도매가격  day_sentiment\n",
       "0    3750.366093  4104       0.000000\n",
       "1    3547.574932  4049       0.000000\n",
       "2    3696.060897  3920      -0.104167\n",
       "3    3770.156364  3917      -0.104167\n",
       "4    3809.974684  4090      -0.104167\n",
       "..           ...   ...            ...\n",
       "620  4547.071429  4718       0.175000\n",
       "621  4373.212544  4749      -0.116270\n",
       "622  4278.649485  4820      -0.116270\n",
       "623  4322.080986  4919      -0.116270\n",
       "624  4138.037190  4988      -0.116270\n",
       "\n",
       "[625 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['경락단가_평균']=df_all['price']\n",
    "\n",
    "df_all\n",
    "\n",
    "df.columns=['경락단가', '도매가격', 'day_sentiment']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5fec77",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df[['day_sentiment','경락단가_평균']]\n",
    "df=df[['경락단가','day_sentiment','도매가격']]\n",
    "\n",
    "\n",
    "# 7일간의 데이터가 입력으로 들어가고 batch size는 임의로 지정\n",
    "seq_length = 5\n",
    "batch = 100\n",
    "\n",
    "# 데이터를 역순으로 정렬하여 전체 데이터의 70% 학습, 30% 테스트에 사용\n",
    "train_size = int(len(df)*0.7)\n",
    "train_set = df[0:train_size]  \n",
    "test_set = df[train_size-seq_length:]\n",
    "\n",
    "# Input scale\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_set.iloc[:, :-1])\n",
    "\n",
    "train_set.iloc[:, :-1] = scaler_x.transform(train_set.iloc[:, :-1])\n",
    "test_set.iloc[:, :-1] = scaler_x.transform(test_set.iloc[:, :-1])\n",
    "\n",
    "# Output scale\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_set.iloc[:, [-1]])\n",
    "\n",
    "train_set.iloc[:, -1:] = scaler_y.transform(train_set.iloc[:, -1:])\n",
    "test_set.iloc[:, -1:] = scaler_y.transform(test_set.iloc[:, -1:])\n",
    "\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series)-seq_length):\n",
    "        _x = time_series[i:i+seq_length, :-1]\n",
    "        _y = time_series[i+seq_length, [-1]]\n",
    "    \n",
    "        # print(_x, \"-->\",_y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = build_dataset(np.array(train_set), seq_length)\n",
    "testX, testY = build_dataset(np.array(test_set), seq_length)\n",
    "\n",
    "# 텐서로 변환\n",
    "trainX_tensor = torch.FloatTensor(trainX)\n",
    "trainY_tensor = torch.FloatTensor(trainY)\n",
    "testX_tensor = torch.FloatTensor(testX)\n",
    "testY_tensor = torch.FloatTensor(testY)\n",
    "\n",
    "# 텐서 형태로 데이터 정의\n",
    "dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
    "\n",
    "# 데이터로더는 기본적으로 2개의 인자를 입력받으며 배치크기는 통상적으로 2의 배수를 사용\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch,\n",
    "                        shuffle=True,  \n",
    "                        drop_last=True)\n",
    "\n",
    "# 설정값\n",
    "data_dim = 2\n",
    "hidden_dim = 10 \n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 100\n",
    "class Net(nn.Module):\n",
    "    # # 기본변수, layer를 초기화해주는 생성자\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len, output_dim, layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=layers,\n",
    "                            # dropout = 0.1,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim, bias = True) \n",
    "        \n",
    "    # 학습 초기화를 위한 함수\n",
    "    def reset_hidden_state(self): \n",
    "        self.hidden = (\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim),\n",
    "                torch.zeros(self.layers, self.seq_len, self.hidden_dim))\n",
    "    \n",
    "    # 예측을 위한 함수\n",
    "    def forward(self, x):\n",
    "        x, _status = self.lstm(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_df, num_epochs = None, lr = None, verbose = 10, patience = 10):\n",
    "     \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    nb_epochs = num_epochs\n",
    "    \n",
    "    # epoch마다 loss 저장\n",
    "    train_hist = np.zeros(nb_epochs)\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = len(train_df)\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_df):\n",
    "\n",
    "            x_train, y_train = samples\n",
    "            x_train=x_train.to(device)\n",
    "            y_train=y_train.to(device)\n",
    "            #print(\"x_train\",x_train)\n",
    "            # seq별 hidden state reset\n",
    "            model.reset_hidden_state()\n",
    "            \n",
    "            # H(x) 계산\n",
    "            outputs = model(x_train)\n",
    "                \n",
    "            # cost 계산\n",
    "            loss = criterion(outputs, y_train)                    \n",
    "            \n",
    "            # cost로 H(x) 개선\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_cost += loss/total_batch\n",
    "               \n",
    "        train_hist[epoch] = avg_cost        \n",
    "        \n",
    "        if epoch % verbose == 0:\n",
    "            print('Epoch:', '%04d' % (epoch), 'train loss :', '{:.4f}'.format(avg_cost))\n",
    "            \n",
    "        # patience번째 마다 early stopping 여부 확인\n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "            \n",
    "            # loss가 커졌다면 early stop\n",
    "            if train_hist[epoch-patience] < train_hist[epoch]:\n",
    "                print('\\n Early Stopping')\n",
    "                \n",
    "                break\n",
    "            \n",
    "    return model.eval(), train_hist\n",
    "\n",
    "# 모델 학습\n",
    "net = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "model, train_hist = train_model(net, dataloader, num_epochs = nb_epochs, lr = learning_rate, verbose = 20, patience = 10)\n",
    "\n",
    "# epoch별 손실값\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 저장    \n",
    "PATH = \"./Timeseries_LSTM_data-02-stock_daily_2.pth\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# 불러오기\n",
    "model = Net(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "model.load_state_dict(torch.load(PATH), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "05dc5ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE SCORE :  778.9570416967734\n",
      "MAE 778.9570416967734\n",
      "MSE 890356.1775922187\n",
      "MSE 943.5868680689758\n",
      "MAPE 22.19071253736312\n"
     ]
    }
   ],
   "source": [
    "def MAE(true, pred):\n",
    "    return np.mean(np.abs(true-pred))\n",
    "\n",
    "print('MAE SCORE : ', MAE(pred_inverse, testY_inverse))\n",
    "\n",
    "#MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE\",mean_absolute_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"MSE\",mean_squared_error(testY_inverse,pred_inverse))\n",
    "\n",
    "#RMSE\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(testY_inverse,pred_inverse)\n",
    "print(\"MSE\",np.sqrt(MSE))\n",
    "# sklearn 은 mse만 제공하기 때문에 rmse는 직접 만들어 써야한다.\n",
    "\n",
    "#MAPE\n",
    "import numpy as np\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "\treturn np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "print(\"MAPE\",MAPE(testY_inverse, pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dcd08ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.plot(np.arange(len(pred_inverse)), pred_inverse, label = 'pred')\n",
    "plt.plot(np.arange(len(testY_inverse)), testY_inverse, label = 'true')\n",
    "plt.title(\"경락단가+감성점수->도매가격\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0eee38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9368f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa6217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96989fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d0ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b084f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a266d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ee253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
